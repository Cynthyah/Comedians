{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Techniques\n",
    "## Input -> clean data, check if the data makes sense\n",
    "## NLP Techniques -> specifically designed for text data\n",
    "## Output -> plot can help to check if we have what we are looking for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Sentiment Analysis\n",
    "### We use the Corpus(original text) to have all words\n",
    "### We use TextBlob (nltk)\n",
    "### We use Naive Bayes (statistical methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.4, subjectivity=0.75)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#                   Polarity                                        Subjectivity\n",
    "#   -1(Negative) <----------->(Positive)+1      0(Objective-fact)<---------------->(Subjective-Opion+1)\n",
    "\n",
    "\n",
    "\n",
    "from textblob import TextBlob\n",
    "TextBlob(\"I love Python\").sentiment\n",
    "TextBlob(\"great\").sentiment # it took the average of the word great\n",
    "TextBlob(\"not great\").sentiment # generally when the word not is infront of word it is Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ali</th>\n",
       "      <td>Ladies and gentlemen, please welcome to the st...</td>\n",
       "      <td>0.073419</td>\n",
       "      <td>0.491160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dave</th>\n",
       "      <td>Original air date: November 07, 2020     [Anno...</td>\n",
       "      <td>0.072256</td>\n",
       "      <td>0.508197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ronny</th>\n",
       "      <td>[“The Evening Primrose (Ye Lai Xiang)” by Li X...</td>\n",
       "      <td>0.111781</td>\n",
       "      <td>0.468166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russel</th>\n",
       "      <td>[TYPING] [CHEERING] NARRATOR: Ladies and gentl...</td>\n",
       "      <td>0.040647</td>\n",
       "      <td>0.521445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               transcript  Polarity  \\\n",
       "Ali     Ladies and gentlemen, please welcome to the st...  0.073419   \n",
       "Dave    Original air date: November 07, 2020     [Anno...  0.072256   \n",
       "Ronny   [“The Evening Primrose (Ye Lai Xiang)” by Li X...  0.111781   \n",
       "Russel  [TYPING] [CHEERING] NARRATOR: Ladies and gentl...  0.040647   \n",
       "\n",
       "        Subjectivity  \n",
       "Ali         0.491160  \n",
       "Dave        0.508197  \n",
       "Ronny       0.468166  \n",
       "Russel      0.521445  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_pickle('files\\\\corpus.pkl')\n",
    "#df_data_clean['transcript']['Dave']\n",
    "pol = lambda x: TextBlob(x).sentiment.polarity\n",
    "sub = lambda x: TextBlob(x).sentiment.subjectivity\n",
    "\n",
    "data['Polarity'] = data['transcript'].apply(pol)\n",
    "data['Subjectivity'] = data['transcript'].apply(sub)\n",
    "data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Fact <----------->Opion\\nSubjectivity')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "for comedian in data.index:\n",
    "    x =  data['Polarity'][comedian]\n",
    "    y = data['Subjectivity'][comedian]\n",
    "    plt.text(x+.001,y+.001, comedian, fontsize=8)\n",
    "    plt.xlim(-.001,.12)\n",
    "    plt.scatter(x,y)\n",
    "plt.xlabel(f\"Negative <-----------> Positive\\nPolarity\")\n",
    "plt.ylabel(f\"Fact <----------->Opion\\nSubjectivity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Topic Modeling\n",
    "### We use the Document-Term Matrix(words) the order does not matter\n",
    "### We use gensim\n",
    "### We use Latent Dirichlet Allocation(LDA) L(hidden), D(type of probability distribution)\n",
    "### We use nltk for some parts of speech tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "#### I like bananas and oranges             Topic A - 100%\n",
    "#### Frogs and fish live in ponds           Topic B - 100%\n",
    "#### Kittens and puppies are fluffy         Topic B - 100%\n",
    "#### I had spinach and apple smothie        Topic A - 100%\n",
    "#### My kitten loves kale                   Topic A -  60% and Topic B - 40% \n",
    "\n",
    "#### Topic A-> 40% banana, 30% kale, 10% breakfast...       Food\n",
    "#### TOpic B-> 30% kitten, 20% puppy, 10% frog, 5% cute...  Animal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Every document is a mix of Topics\n",
    "#### Every topic is a mix of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absorb</th>\n",
       "      <th>abuela</th>\n",
       "      <th>abundance</th>\n",
       "      <th>abuse</th>\n",
       "      <th>accent</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>access</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>zero</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zipped</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ali</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dave</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ronny</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russel</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 3151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        able  absolutely  absorb  abuela  abundance  abuse  accent  accept  \\\n",
       "Ali        0           0       1       1          0      0       0       1   \n",
       "Dave       0           0       0       0          0      0       2       0   \n",
       "Ronny      0           0       0       0          3      0       0       1   \n",
       "Russel     4           1       0       0          0      1       0       1   \n",
       "\n",
       "        acceptable  access  ...  york  young  younger  zero  zhong  zipped  \\\n",
       "Ali              1       0  ...     0      3        1     2      0       0   \n",
       "Dave             0       0  ...     2      2        0     0      0       0   \n",
       "Ronny            0       0  ...    22      0        0     1      1       1   \n",
       "Russel           0       1  ...     0      1        2     0      0       0   \n",
       "\n",
       "        zodiac  zone  zones  zoom  \n",
       "Ali          0     1      0     0  \n",
       "Dave         0     0      0     2  \n",
       "Ronny        0     1      1     0  \n",
       "Russel       1     0      0     0  \n",
       "\n",
       "[4 rows x 3151 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using gensin to do all the work behind the separation of topic and words\n",
    "# We need to inform the document-term matrix, number of topics and number of iterations\n",
    "data = pd.read_pickle('files\\\\dtm_stop.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ali</th>\n",
       "      <th>Dave</th>\n",
       "      <th>Ronny</th>\n",
       "      <th>Russel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absolutely</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absorb</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abuela</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abundance</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Ali  Dave  Ronny  Russel\n",
       "able          0     0      0       4\n",
       "absolutely    0     0      0       1\n",
       "absorb        1     0      0       0\n",
       "abuela        1     0      0       0\n",
       "abundance     0     0      3       0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to use gensim first install -> conda install -c conda-forge gensim\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.matutils.Sparse2Corpus at 0x1bfe07b3688>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to put the document-term matrix into a new gensim format\n",
    "# from df -> sparse matrix\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gensim requires dictionary of the all terms and theirs respective location in the term-document matrix\n",
    "import pickle\n",
    "\n",
    "cv = pickle.load(open(\"files\\\\cv_stop.pkl\",\"rb\"))\n",
    "id2word = dict((v,k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt #1 - Topics in generall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"goes\" + 0.000*\"baby\" + 0.000*\"black\" + 0.000*\"think\" + 0.000*\"indian\" + 0.000*\"tell\" + 0.000*\"white\" + 0.000*\"fucking\" + 0.000*\"need\" + 0.000*\"make\"'),\n",
       " (1,\n",
       "  '0.000*\"black\" + 0.000*\"goes\" + 0.000*\"way\" + 0.000*\"white\" + 0.000*\"america\" + 0.000*\"think\" + 0.000*\"ll\" + 0.000*\"ve\" + 0.000*\"need\" + 0.000*\"guy\"'),\n",
       " (2,\n",
       "  '0.012*\"black\" + 0.009*\"remember\" + 0.008*\"white\" + 0.007*\"guy\" + 0.007*\"life\" + 0.007*\"mask\" + 0.006*\"way\" + 0.006*\"helicopter\" + 0.006*\"coronavirus\" + 0.005*\"ve\"'),\n",
       " (3,\n",
       "  '0.008*\"goes\" + 0.006*\"fucking\" + 0.005*\"indian\" + 0.005*\"america\" + 0.005*\"need\" + 0.004*\"baby\" + 0.004*\"way\" + 0.004*\"think\" + 0.004*\"ll\" + 0.004*\"make\"')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we need to specify 2 other parameters as well\n",
    "# the number of topics and the number of passes\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt #2 - Only Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to pull out nouns from a string of text\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    '''Give a string of text, tokenize the text and pull out only the nouns'''\n",
    "    is_noun = lambda pos:pos[:2] == \"NN\"\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for word,pos in pos_tag(tokenized) if is_noun(pos)]\n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>fullname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ali</th>\n",
       "      <td>ladies and gentlemen please welcome to the sta...</td>\n",
       "      <td>Ali Wong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dave</th>\n",
       "      <td>original air date november        ladies and g...</td>\n",
       "      <td>Dave Johns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ronny</th>\n",
       "      <td>ladies and gentlemen ronny chieng   thank ...</td>\n",
       "      <td>Ronny Belford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russel</th>\n",
       "      <td>narrator ladies and gentlemen it’s start tim...</td>\n",
       "      <td>Russel Raise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               transcript       fullname\n",
       "Ali     ladies and gentlemen please welcome to the sta...       Ali Wong\n",
       "Dave    original air date november        ladies and g...     Dave Johns\n",
       "Ronny       ladies and gentlemen ronny chieng   thank ...  Ronny Belford\n",
       "Russel    narrator ladies and gentlemen it’s start tim...   Russel Raise"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the cleaned data, before the CounterVectorizer step\n",
    "data_clean = pd.read_pickle('files\\\\data_clean.pkl')\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ali</th>\n",
       "      <td>ladies gentlemen stage ali y y ’ t gon ’ ’ osi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dave</th>\n",
       "      <td>air date november ladies gentlemen chappelle d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ronny</th>\n",
       "      <td>ladies gentlemen chieng get guys kind thank vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russel</th>\n",
       "      <td>narrator ladies gentlemen ’ start time dome st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               transcript\n",
       "Ali     ladies gentlemen stage ali y y ’ t gon ’ ’ osi...\n",
       "Dave    air date november ladies gentlemen chappelle d...\n",
       "Ronny   ladies gentlemen chieng get guys kind thank vi...\n",
       "Russel  narrator ladies gentlemen ’ start time dome st..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the nouns function to the transcript to filter only nouns\n",
    "data_nouns = pd.DataFrame(data_clean.transcript.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abundance</th>\n",
       "      <th>abuse</th>\n",
       "      <th>accent</th>\n",
       "      <th>access</th>\n",
       "      <th>account</th>\n",
       "      <th>accountability</th>\n",
       "      <th>accounts</th>\n",
       "      <th>ace</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>...</th>\n",
       "      <th>yank</th>\n",
       "      <th>yard</th>\n",
       "      <th>yards</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>york</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ali</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dave</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ronny</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russel</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 1849 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        abundance  abuse  accent  access  account  accountability  accounts  \\\n",
       "Ali             0      0       0       0        3               0         0   \n",
       "Dave            0      0       2       0        2               0         2   \n",
       "Ronny           3      0       0       0        0               0         0   \n",
       "Russel          0      1       0       1        0               1         0   \n",
       "\n",
       "        ace  act  action  ...  yank  yard  yards  yelp  yo  yoga  yogurt  \\\n",
       "Ali       0    0       0  ...     1     0      0     0   0     1       0   \n",
       "Dave      0    0       0  ...     0     2      0     0   0     0       0   \n",
       "Ronny     1    0       3  ...     0     0      1     1  12     0       0   \n",
       "Russel    0    2       0  ...     0     0      0     0   4     0      12   \n",
       "\n",
       "        york  zone  zoom  \n",
       "Ali        0     1     0  \n",
       "Dave       2     0     2  \n",
       "Ronny     22     1     0  \n",
       "Russel     0     0     0  \n",
       "\n",
       "[4 rows x 1849 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now whe know some other stopwords related to the nouns\n",
    "# Lets update our document-term matrix with the new list of stop words\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# another word to stopwords\n",
    "add_stop_words = ['like','im','know','just','thats','people','youre','think','yeah','said','year','years','yes']\n",
    "\n",
    "# add new stop words\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# re-create document-term matrix\n",
    "cvn = CountVectorizer(stop_words=stop_words) # using the new stopwords\n",
    "data_cvn = cvn.fit_transform(data_nouns.transcript)  # apply into column transcript\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(),columns=cvn.get_feature_names()) # create another df with the words and frequency\n",
    "data_dtmn.index = data_nouns.index # use the index from df \n",
    "data_dtmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the gensim corpus\n",
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n",
    "\n",
    "# create the vocabulary dictionary\n",
    "id2wordn = dict((v,k) for k,v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.014*\"man\" + 0.014*\"guy\" + 0.014*\"life\" + 0.014*\"mask\" + 0.011*\"way\" + 0.011*\"coronavirus\" + 0.011*\"helicopter\" + 0.009*\"day\" + 0.008*\"time\" + 0.008*\"house\"'),\n",
       " (1,\n",
       "  '0.001*\"time\" + 0.001*\"way\" + 0.001*\"shit\" + 0.001*\"day\" + 0.001*\"baby\" + 0.001*\"man\" + 0.001*\"right\" + 0.001*\"guy\" + 0.001*\"peters\" + 0.001*\"kids\"'),\n",
       " (2,\n",
       "  '0.014*\"time\" + 0.010*\"america\" + 0.010*\"fuck\" + 0.010*\"way\" + 0.008*\"right\" + 0.007*\"wife\" + 0.007*\"parents\" + 0.007*\"shit\" + 0.007*\"train\" + 0.007*\"don\"'),\n",
       " (3,\n",
       "  '0.020*\"baby\" + 0.010*\"husband\" + 0.010*\"shit\" + 0.008*\"day\" + 0.008*\"time\" + 0.007*\"mom\" + 0.007*\"man\" + 0.007*\"lot\" + 0.006*\"pussy\" + 0.005*\"fuck\"')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets start with 4 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=4, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt #3 - Only Nouns/Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouns_adj(text):\n",
    "    '''Give a string of text, tokenize the text and pull out only the nouns or adjetives'''\n",
    "    is_noun_adj = lambda pos:pos[:2] == \"NN\" or pos[:2] == \"JJ\"\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for word,pos in pos_tag(tokenized) if is_noun_adj(pos)]\n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ali</th>\n",
       "      <td>ladies gentlemen welcome stage ali y y wasn ’ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dave</th>\n",
       "      <td>original air date november ladies gentlemen ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ronny</th>\n",
       "      <td>ladies gentlemen chieng ta get ta guys s kind ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russel</th>\n",
       "      <td>narrator ladies gentlemen ’ s start time dome ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               transcript\n",
       "Ali     ladies gentlemen welcome stage ali y y wasn ’ ...\n",
       "Dave    original air date november ladies gentlemen ch...\n",
       "Ronny   ladies gentlemen chieng ta get ta guys s kind ...\n",
       "Russel  narrator ladies gentlemen ’ s start time dome ..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the nouns function to the transcript to filter only nouns or adjetives\n",
    "data_nouns_adj = pd.DataFrame(data_clean.transcript.apply(nouns_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>abuela</th>\n",
       "      <th>abundance</th>\n",
       "      <th>abuse</th>\n",
       "      <th>accent</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>access</th>\n",
       "      <th>account</th>\n",
       "      <th>accountability</th>\n",
       "      <th>accounts</th>\n",
       "      <th>...</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ali</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dave</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ronny</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russel</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 2212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        able  abuela  abundance  abuse  accent  acceptable  access  account  \\\n",
       "Ali        0       1          0      0       0           1       0        3   \n",
       "Dave       0       0          0      0       2           0       0        2   \n",
       "Ronny      0       0          3      0       0           0       0        0   \n",
       "Russel     4       0          0      1       0           0       1        0   \n",
       "\n",
       "        accountability  accounts  ...  yo  yoga  yogurt  york  young  younger  \\\n",
       "Ali                  0         0  ...   0     1       0     0      3        1   \n",
       "Dave                 0         2  ...   0     0       0     2      2        0   \n",
       "Ronny                0         0  ...  13     0       0    22      0        0   \n",
       "Russel               1         0  ...   4     0      12     0      1        2   \n",
       "\n",
       "        zhong  zodiac  zone  zoom  \n",
       "Ali         0       0     1     0  \n",
       "Dave        0       0     0     2  \n",
       "Ronny       1       0     1     0  \n",
       "Russel      0       1     0     0  \n",
       "\n",
       "[4 rows x 2212 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new document-term matrix using only nouns and adjectives, remore common words\n",
    "# re-create document-term matrix\n",
    "cvna = CountVectorizer(stop_words=stop_words, max_df=.8) # using the new stopwords\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.transcript)  # apply into column transcript\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(),columns=cvna.get_feature_names()) # create another df with the words and frequency\n",
    "data_dtmna.index = data_nouns_adj.index # use the index from df \n",
    "data_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the gensim corpus\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "\n",
    "# create the vocabulary dictionary\n",
    "id2wordna = dict((v,k) for k,v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"fuck\" + 0.001*\"indian\" + 0.001*\"guy\" + 0.001*\"america\" + 0.001*\"wife\" + 0.001*\"state\" + 0.001*\"okay\" + 0.001*\"fucking\" + 0.001*\"russell\" + 0.001*\"shit\"'),\n",
       " (1,\n",
       "  '0.018*\"baby\" + 0.009*\"shit\" + 0.009*\"husband\" + 0.007*\"pussy\" + 0.007*\"mom\" + 0.006*\"dick\" + 0.005*\"fuck\" + 0.004*\"okay\" + 0.004*\"girl\" + 0.004*\"ali\"'),\n",
       " (2,\n",
       "  '0.021*\"indian\" + 0.011*\"russell\" + 0.010*\"peters\" + 0.010*\"ok\" + 0.009*\"nose\" + 0.009*\"son\" + 0.008*\"fact\" + 0.008*\"fuck\" + 0.008*\"india\" + 0.008*\"shit\"'),\n",
       " (3,\n",
       "  '0.015*\"america\" + 0.009*\"okay\" + 0.008*\"guy\" + 0.008*\"fuck\" + 0.008*\"train\" + 0.008*\"york\" + 0.008*\"wife\" + 0.008*\"state\" + 0.007*\"chinese\" + 0.007*\"asian\"')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets start with 4 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Topics in Each Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"fuck\" + 0.001*\"indian\" + 0.001*\"guy\" + 0.001*\"america\" + 0.001*\"wife\" + 0.001*\"state\" + 0.001*\"okay\" + 0.001*\"fucking\" + 0.001*\"russell\" + 0.001*\"shit\"'),\n",
       " (1,\n",
       "  '0.018*\"baby\" + 0.009*\"shit\" + 0.009*\"husband\" + 0.007*\"pussy\" + 0.007*\"mom\" + 0.006*\"dick\" + 0.005*\"fuck\" + 0.004*\"okay\" + 0.004*\"girl\" + 0.004*\"ali\"'),\n",
       " (2,\n",
       "  '0.021*\"indian\" + 0.011*\"russell\" + 0.010*\"peters\" + 0.010*\"ok\" + 0.009*\"nose\" + 0.009*\"son\" + 0.008*\"fact\" + 0.008*\"fuck\" + 0.008*\"india\" + 0.008*\"shit\"'),\n",
       " (3,\n",
       "  '0.015*\"america\" + 0.009*\"okay\" + 0.008*\"guy\" + 0.008*\"fuck\" + 0.008*\"train\" + 0.008*\"york\" + 0.008*\"wife\" + 0.008*\"state\" + 0.007*\"chinese\" + 0.007*\"asian\"')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our final LDA model\n",
    "ldna = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=80)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics\n",
    "#### Topic 0: train,wife,chinese,asian\n",
    "#### Topic 1: indian, russel, asian, chinese\n",
    "#### Topic 2: coronavirus, mask, helicopter, president, meeting, cold\n",
    "#### Topic 3: indian, russel, nose, son, india"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Ali'), (3, 'Dave'), (3, 'Ronny'), (2, 'Russel')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, take a look at which topic each transcript contains\n",
    "corpus_transformed = ldana[corpusna]\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data_dtmna.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics\n",
    "#### Topic 0: train,wife,chinese,asian                                      ->Ronny\n",
    "#### Topic 1: indian, russel, asian, chinese                                ->Nobody\n",
    "#### Topic 2: coronavirus, mask, helicopter, president, meeting, cold       ->Dave\n",
    "#### Topic 3: indian, russel, nose, son, india                              ->Russel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
